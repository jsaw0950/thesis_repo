{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69b54c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from pydbgen import pydbgen\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, # 1000 observations \n",
    "    n_features=25, # 5 total features\n",
    "    n_informative=10, # 3 'useful' features\n",
    "    n_classes=2, # binary target/label \n",
    "    random_state=999 # if you want the same results as mine\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef3b84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = pd.DataFrame([str(i) for i in range(20)])\n",
    "col_2 = pd.DataFrame(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\n",
    "col_3 = pd.DataFrame(['ab', 'cd', 'ef', 'gh'])\n",
    "col_4 = pd.DataFrame(['asl', 'sa', 'dsf', 'ei49'])\n",
    "col_5 = pd.DataFrame(['yeas', 'nahs'])\n",
    "\n",
    "\n",
    "input_1 = col_1.sample(n=10000, random_state = 1, replace = True).reset_index()\n",
    "input_2 = col_2.sample(n=10000, random_state = 1, replace = True).reset_index()\n",
    "input_3 = col_3.sample(n=10000, random_state = 1, replace = True).reset_index()\n",
    "input_4 = col_4.sample(n=10000, random_state = 1, replace = True).reset_index()\n",
    "input_5 = col_5.sample(n=10000, random_state = 1, replace = True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "494ed2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "X = X.reset_index()\n",
    "# X['country'] = input_1[0].astype('category')\n",
    "# X['city'] = input_2[0].astype('category')\n",
    "# X['state'] = input_3[0].astype('category')\n",
    "# X['year'] = input_4[0].astype('category')\n",
    "# X['stuff'] = input_5[0].astype('category')\n",
    "X = X.iloc[:, 1:]\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "654de172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.426669</td>\n",
       "      <td>1.594298</td>\n",
       "      <td>0.602572</td>\n",
       "      <td>0.249568</td>\n",
       "      <td>0.165646</td>\n",
       "      <td>0.816636</td>\n",
       "      <td>0.156962</td>\n",
       "      <td>0.845028</td>\n",
       "      <td>-0.116824</td>\n",
       "      <td>-0.532176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.993854</td>\n",
       "      <td>1.313586</td>\n",
       "      <td>-2.137797</td>\n",
       "      <td>0.461462</td>\n",
       "      <td>-0.351886</td>\n",
       "      <td>3.374217</td>\n",
       "      <td>1.543696</td>\n",
       "      <td>-3.381315</td>\n",
       "      <td>-0.246753</td>\n",
       "      <td>1.268339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142478</td>\n",
       "      <td>-1.378403</td>\n",
       "      <td>-0.312876</td>\n",
       "      <td>-0.025111</td>\n",
       "      <td>6.488193</td>\n",
       "      <td>-3.369347</td>\n",
       "      <td>0.410162</td>\n",
       "      <td>0.388187</td>\n",
       "      <td>1.085155</td>\n",
       "      <td>0.125385</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051849</td>\n",
       "      <td>-3.229839</td>\n",
       "      <td>-2.470495</td>\n",
       "      <td>1.473758</td>\n",
       "      <td>0.526669</td>\n",
       "      <td>0.060711</td>\n",
       "      <td>2.297547</td>\n",
       "      <td>3.099285</td>\n",
       "      <td>-0.670223</td>\n",
       "      <td>0.560932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.958750</td>\n",
       "      <td>-0.525450</td>\n",
       "      <td>1.804392</td>\n",
       "      <td>-0.461491</td>\n",
       "      <td>0.985691</td>\n",
       "      <td>-2.009606</td>\n",
       "      <td>-3.469679</td>\n",
       "      <td>-0.212911</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>-0.572119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030304</td>\n",
       "      <td>4.689434</td>\n",
       "      <td>-0.181685</td>\n",
       "      <td>-0.125351</td>\n",
       "      <td>-1.017432</td>\n",
       "      <td>-0.923070</td>\n",
       "      <td>-2.740200</td>\n",
       "      <td>-1.796509</td>\n",
       "      <td>-1.105280</td>\n",
       "      <td>0.072605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.940204</td>\n",
       "      <td>-0.448915</td>\n",
       "      <td>2.004946</td>\n",
       "      <td>0.798871</td>\n",
       "      <td>0.729743</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>-3.333892</td>\n",
       "      <td>-0.602083</td>\n",
       "      <td>-0.437864</td>\n",
       "      <td>1.091887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304618</td>\n",
       "      <td>2.318512</td>\n",
       "      <td>-1.064451</td>\n",
       "      <td>-0.368093</td>\n",
       "      <td>2.412781</td>\n",
       "      <td>-0.243437</td>\n",
       "      <td>-1.957203</td>\n",
       "      <td>-0.904998</td>\n",
       "      <td>1.312101</td>\n",
       "      <td>0.744369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.387104</td>\n",
       "      <td>-0.514536</td>\n",
       "      <td>1.182109</td>\n",
       "      <td>-2.058765</td>\n",
       "      <td>-2.399117</td>\n",
       "      <td>1.451931</td>\n",
       "      <td>-0.777646</td>\n",
       "      <td>-0.117315</td>\n",
       "      <td>-1.576506</td>\n",
       "      <td>-1.172309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799516</td>\n",
       "      <td>-0.060043</td>\n",
       "      <td>-0.664849</td>\n",
       "      <td>-1.795065</td>\n",
       "      <td>-2.223622</td>\n",
       "      <td>0.231865</td>\n",
       "      <td>1.085187</td>\n",
       "      <td>-3.349167</td>\n",
       "      <td>0.579290</td>\n",
       "      <td>-0.308433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.426669  1.594298  0.602572  0.249568  0.165646  0.816636  0.156962   \n",
       "1  0.142478 -1.378403 -0.312876 -0.025111  6.488193 -3.369347  0.410162   \n",
       "2  0.958750 -0.525450  1.804392 -0.461491  0.985691 -2.009606 -3.469679   \n",
       "3  1.940204 -0.448915  2.004946  0.798871  0.729743  0.264706 -3.333892   \n",
       "4 -0.387104 -0.514536  1.182109 -2.058765 -2.399117  1.451931 -0.777646   \n",
       "\n",
       "         7         8         9   ...        15        16        17        18  \\\n",
       "0  0.845028 -0.116824 -0.532176  ...  1.993854  1.313586 -2.137797  0.461462   \n",
       "1  0.388187  1.085155  0.125385  ...  1.051849 -3.229839 -2.470495  1.473758   \n",
       "2 -0.212911  0.381410 -0.572119  ... -0.030304  4.689434 -0.181685 -0.125351   \n",
       "3 -0.602083 -0.437864  1.091887  ...  0.304618  2.318512 -1.064451 -0.368093   \n",
       "4 -0.117315 -1.576506 -1.172309  ...  0.799516 -0.060043 -0.664849 -1.795065   \n",
       "\n",
       "         19        20        21        22        23        24  \n",
       "0 -0.351886  3.374217  1.543696 -3.381315 -0.246753  1.268339  \n",
       "1  0.526669  0.060711  2.297547  3.099285 -0.670223  0.560932  \n",
       "2 -1.017432 -0.923070 -2.740200 -1.796509 -1.105280  0.072605  \n",
       "3  2.412781 -0.243437 -1.957203 -0.904998  1.312101  0.744369  \n",
       "4 -2.223622  0.231865  1.085187 -3.349167  0.579290 -0.308433  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21b56999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#y = np.where(((X['country'] == 'Congo')), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b79c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c739cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e2bd71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.5\n",
      "[1]\ttraining's auc: 0.909814\ttraining's binary_logloss: 0.641415\tvalid_1's auc: 0.892723\tvalid_1's binary_logloss: 0.643746\n",
      "[2]\ttraining's auc: 0.924169\ttraining's binary_logloss: 0.598026\tvalid_1's auc: 0.911688\tvalid_1's binary_logloss: 0.601913\n",
      "[3]\ttraining's auc: 0.935933\ttraining's binary_logloss: 0.560733\tvalid_1's auc: 0.916657\tvalid_1's binary_logloss: 0.567508\n",
      "[4]\ttraining's auc: 0.9403\ttraining's binary_logloss: 0.529551\tvalid_1's auc: 0.924994\tvalid_1's binary_logloss: 0.536534\n",
      "[5]\ttraining's auc: 0.947641\ttraining's binary_logloss: 0.499888\tvalid_1's auc: 0.930466\tvalid_1's binary_logloss: 0.510285\n",
      "[6]\ttraining's auc: 0.950194\ttraining's binary_logloss: 0.475591\tvalid_1's auc: 0.933305\tvalid_1's binary_logloss: 0.486832\n",
      "[7]\ttraining's auc: 0.951916\ttraining's binary_logloss: 0.454466\tvalid_1's auc: 0.936036\tvalid_1's binary_logloss: 0.466983\n",
      "[8]\ttraining's auc: 0.954333\ttraining's binary_logloss: 0.433893\tvalid_1's auc: 0.939037\tvalid_1's binary_logloss: 0.447182\n",
      "[9]\ttraining's auc: 0.955881\ttraining's binary_logloss: 0.416493\tvalid_1's auc: 0.939534\tvalid_1's binary_logloss: 0.432193\n",
      "[10]\ttraining's auc: 0.956947\ttraining's binary_logloss: 0.400628\tvalid_1's auc: 0.940773\tvalid_1's binary_logloss: 0.417806\n",
      "[11]\ttraining's auc: 0.959626\ttraining's binary_logloss: 0.385643\tvalid_1's auc: 0.942862\tvalid_1's binary_logloss: 0.404633\n",
      "[12]\ttraining's auc: 0.962223\ttraining's binary_logloss: 0.371084\tvalid_1's auc: 0.945446\tvalid_1's binary_logloss: 0.391606\n",
      "[13]\ttraining's auc: 0.964613\ttraining's binary_logloss: 0.358108\tvalid_1's auc: 0.947715\tvalid_1's binary_logloss: 0.38044\n",
      "[14]\ttraining's auc: 0.967216\ttraining's binary_logloss: 0.345\tvalid_1's auc: 0.950054\tvalid_1's binary_logloss: 0.36875\n",
      "[15]\ttraining's auc: 0.968767\ttraining's binary_logloss: 0.333942\tvalid_1's auc: 0.952112\tvalid_1's binary_logloss: 0.358213\n",
      "[16]\ttraining's auc: 0.970193\ttraining's binary_logloss: 0.323908\tvalid_1's auc: 0.953484\tvalid_1's binary_logloss: 0.349431\n",
      "[17]\ttraining's auc: 0.971633\ttraining's binary_logloss: 0.313303\tvalid_1's auc: 0.955179\tvalid_1's binary_logloss: 0.339534\n",
      "[18]\ttraining's auc: 0.973172\ttraining's binary_logloss: 0.303589\tvalid_1's auc: 0.957017\tvalid_1's binary_logloss: 0.33089\n",
      "[19]\ttraining's auc: 0.974154\ttraining's binary_logloss: 0.294814\tvalid_1's auc: 0.958089\tvalid_1's binary_logloss: 0.323145\n",
      "[20]\ttraining's auc: 0.975254\ttraining's binary_logloss: 0.286895\tvalid_1's auc: 0.959293\tvalid_1's binary_logloss: 0.316245\n",
      "[21]\ttraining's auc: 0.97683\ttraining's binary_logloss: 0.278824\tvalid_1's auc: 0.960812\tvalid_1's binary_logloss: 0.309391\n",
      "[22]\ttraining's auc: 0.977614\ttraining's binary_logloss: 0.271752\tvalid_1's auc: 0.962169\tvalid_1's binary_logloss: 0.302488\n",
      "[23]\ttraining's auc: 0.979491\ttraining's binary_logloss: 0.262514\tvalid_1's auc: 0.964476\tvalid_1's binary_logloss: 0.294358\n",
      "[24]\ttraining's auc: 0.980382\ttraining's binary_logloss: 0.255189\tvalid_1's auc: 0.965834\tvalid_1's binary_logloss: 0.287707\n",
      "[25]\ttraining's auc: 0.98119\ttraining's binary_logloss: 0.248147\tvalid_1's auc: 0.967022\tvalid_1's binary_logloss: 0.28113\n",
      "[26]\ttraining's auc: 0.981968\ttraining's binary_logloss: 0.242685\tvalid_1's auc: 0.967948\tvalid_1's binary_logloss: 0.276027\n",
      "[27]\ttraining's auc: 0.98305\ttraining's binary_logloss: 0.235441\tvalid_1's auc: 0.969298\tvalid_1's binary_logloss: 0.26972\n",
      "[28]\ttraining's auc: 0.983707\ttraining's binary_logloss: 0.230415\tvalid_1's auc: 0.969992\tvalid_1's binary_logloss: 0.265453\n",
      "[29]\ttraining's auc: 0.984431\ttraining's binary_logloss: 0.224132\tvalid_1's auc: 0.971008\tvalid_1's binary_logloss: 0.259784\n",
      "[30]\ttraining's auc: 0.985124\ttraining's binary_logloss: 0.218839\tvalid_1's auc: 0.971907\tvalid_1's binary_logloss: 0.254916\n",
      "[31]\ttraining's auc: 0.985734\ttraining's binary_logloss: 0.21374\tvalid_1's auc: 0.972513\tvalid_1's binary_logloss: 0.250537\n",
      "[32]\ttraining's auc: 0.986584\ttraining's binary_logloss: 0.207766\tvalid_1's auc: 0.973533\tvalid_1's binary_logloss: 0.245694\n",
      "[33]\ttraining's auc: 0.98712\ttraining's binary_logloss: 0.202853\tvalid_1's auc: 0.973888\tvalid_1's binary_logloss: 0.242523\n",
      "[34]\ttraining's auc: 0.987358\ttraining's binary_logloss: 0.199626\tvalid_1's auc: 0.97407\tvalid_1's binary_logloss: 0.23992\n",
      "[35]\ttraining's auc: 0.987943\ttraining's binary_logloss: 0.194668\tvalid_1's auc: 0.974764\tvalid_1's binary_logloss: 0.235663\n",
      "[36]\ttraining's auc: 0.988579\ttraining's binary_logloss: 0.19008\tvalid_1's auc: 0.975538\tvalid_1's binary_logloss: 0.231621\n",
      "[37]\ttraining's auc: 0.988915\ttraining's binary_logloss: 0.186681\tvalid_1's auc: 0.975795\tvalid_1's binary_logloss: 0.228713\n",
      "[38]\ttraining's auc: 0.989468\ttraining's binary_logloss: 0.182319\tvalid_1's auc: 0.976323\tvalid_1's binary_logloss: 0.225288\n",
      "[39]\ttraining's auc: 0.990049\ttraining's binary_logloss: 0.178013\tvalid_1's auc: 0.976948\tvalid_1's binary_logloss: 0.221658\n",
      "[40]\ttraining's auc: 0.990534\ttraining's binary_logloss: 0.174199\tvalid_1's auc: 0.977527\tvalid_1's binary_logloss: 0.218708\n",
      "[41]\ttraining's auc: 0.990829\ttraining's binary_logloss: 0.170778\tvalid_1's auc: 0.977881\tvalid_1's binary_logloss: 0.215974\n",
      "[42]\ttraining's auc: 0.99118\ttraining's binary_logloss: 0.168104\tvalid_1's auc: 0.978101\tvalid_1's binary_logloss: 0.214369\n",
      "[43]\ttraining's auc: 0.991545\ttraining's binary_logloss: 0.16459\tvalid_1's auc: 0.978449\tvalid_1's binary_logloss: 0.211828\n",
      "[44]\ttraining's auc: 0.99188\ttraining's binary_logloss: 0.162282\tvalid_1's auc: 0.978907\tvalid_1's binary_logloss: 0.209642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Jack\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45]\ttraining's auc: 0.992234\ttraining's binary_logloss: 0.159017\tvalid_1's auc: 0.979137\tvalid_1's binary_logloss: 0.207549\n",
      "[46]\ttraining's auc: 0.992538\ttraining's binary_logloss: 0.155791\tvalid_1's auc: 0.979473\tvalid_1's binary_logloss: 0.205373\n",
      "[47]\ttraining's auc: 0.992823\ttraining's binary_logloss: 0.153007\tvalid_1's auc: 0.979952\tvalid_1's binary_logloss: 0.202937\n",
      "[48]\ttraining's auc: 0.993089\ttraining's binary_logloss: 0.151213\tvalid_1's auc: 0.980081\tvalid_1's binary_logloss: 0.201892\n",
      "[49]\ttraining's auc: 0.993368\ttraining's binary_logloss: 0.147769\tvalid_1's auc: 0.980449\tvalid_1's binary_logloss: 0.199376\n",
      "[50]\ttraining's auc: 0.993574\ttraining's binary_logloss: 0.145874\tvalid_1's auc: 0.980597\tvalid_1's binary_logloss: 0.19834\n",
      "[51]\ttraining's auc: 0.993808\ttraining's binary_logloss: 0.143986\tvalid_1's auc: 0.980726\tvalid_1's binary_logloss: 0.197475\n",
      "[52]\ttraining's auc: 0.994085\ttraining's binary_logloss: 0.141076\tvalid_1's auc: 0.981075\tvalid_1's binary_logloss: 0.195275\n",
      "[53]\ttraining's auc: 0.994282\ttraining's binary_logloss: 0.139341\tvalid_1's auc: 0.981023\tvalid_1's binary_logloss: 0.194743\n",
      "[54]\ttraining's auc: 0.994531\ttraining's binary_logloss: 0.137105\tvalid_1's auc: 0.981456\tvalid_1's binary_logloss: 0.19274\n",
      "[55]\ttraining's auc: 0.994812\ttraining's binary_logloss: 0.134649\tvalid_1's auc: 0.981626\tvalid_1's binary_logloss: 0.191085\n",
      "[56]\ttraining's auc: 0.995056\ttraining's binary_logloss: 0.133251\tvalid_1's auc: 0.981534\tvalid_1's binary_logloss: 0.191087\n",
      "[57]\ttraining's auc: 0.995294\ttraining's binary_logloss: 0.131695\tvalid_1's auc: 0.981589\tvalid_1's binary_logloss: 0.190704\n",
      "[58]\ttraining's auc: 0.99545\ttraining's binary_logloss: 0.129571\tvalid_1's auc: 0.981765\tvalid_1's binary_logloss: 0.189123\n",
      "[59]\ttraining's auc: 0.995633\ttraining's binary_logloss: 0.128306\tvalid_1's auc: 0.981803\tvalid_1's binary_logloss: 0.188925\n",
      "[60]\ttraining's auc: 0.995772\ttraining's binary_logloss: 0.126053\tvalid_1's auc: 0.981948\tvalid_1's binary_logloss: 0.187245\n",
      "[61]\ttraining's auc: 0.995967\ttraining's binary_logloss: 0.124548\tvalid_1's auc: 0.981936\tvalid_1's binary_logloss: 0.187005\n",
      "[62]\ttraining's auc: 0.996112\ttraining's binary_logloss: 0.122792\tvalid_1's auc: 0.98209\tvalid_1's binary_logloss: 0.185911\n",
      "[63]\ttraining's auc: 0.996243\ttraining's binary_logloss: 0.120729\tvalid_1's auc: 0.982354\tvalid_1's binary_logloss: 0.184266\n",
      "[64]\ttraining's auc: 0.996393\ttraining's binary_logloss: 0.119465\tvalid_1's auc: 0.982419\tvalid_1's binary_logloss: 0.183934\n",
      "[65]\ttraining's auc: 0.996542\ttraining's binary_logloss: 0.118217\tvalid_1's auc: 0.982417\tvalid_1's binary_logloss: 0.183573\n",
      "[66]\ttraining's auc: 0.996671\ttraining's binary_logloss: 0.116516\tvalid_1's auc: 0.982699\tvalid_1's binary_logloss: 0.182264\n",
      "[67]\ttraining's auc: 0.996855\ttraining's binary_logloss: 0.115051\tvalid_1's auc: 0.982863\tvalid_1's binary_logloss: 0.181339\n",
      "[68]\ttraining's auc: 0.997016\ttraining's binary_logloss: 0.113777\tvalid_1's auc: 0.982905\tvalid_1's binary_logloss: 0.181106\n",
      "[69]\ttraining's auc: 0.997095\ttraining's binary_logloss: 0.112324\tvalid_1's auc: 0.983131\tvalid_1's binary_logloss: 0.179853\n",
      "[70]\ttraining's auc: 0.997266\ttraining's binary_logloss: 0.111244\tvalid_1's auc: 0.983039\tvalid_1's binary_logloss: 0.180092\n",
      "[71]\ttraining's auc: 0.997408\ttraining's binary_logloss: 0.110082\tvalid_1's auc: 0.983083\tvalid_1's binary_logloss: 0.179838\n",
      "[72]\ttraining's auc: 0.997544\ttraining's binary_logloss: 0.108873\tvalid_1's auc: 0.983121\tvalid_1's binary_logloss: 0.179496\n",
      "[73]\ttraining's auc: 0.997631\ttraining's binary_logloss: 0.107426\tvalid_1's auc: 0.983192\tvalid_1's binary_logloss: 0.178741\n",
      "[74]\ttraining's auc: 0.997729\ttraining's binary_logloss: 0.106163\tvalid_1's auc: 0.983382\tvalid_1's binary_logloss: 0.177732\n",
      "[75]\ttraining's auc: 0.997829\ttraining's binary_logloss: 0.105097\tvalid_1's auc: 0.983366\tvalid_1's binary_logloss: 0.177524\n",
      "[76]\ttraining's auc: 0.997882\ttraining's binary_logloss: 0.104165\tvalid_1's auc: 0.983419\tvalid_1's binary_logloss: 0.176881\n",
      "[77]\ttraining's auc: 0.99799\ttraining's binary_logloss: 0.103086\tvalid_1's auc: 0.983583\tvalid_1's binary_logloss: 0.176084\n",
      "[78]\ttraining's auc: 0.998098\ttraining's binary_logloss: 0.102004\tvalid_1's auc: 0.983602\tvalid_1's binary_logloss: 0.175926\n",
      "[79]\ttraining's auc: 0.998154\ttraining's binary_logloss: 0.100683\tvalid_1's auc: 0.983614\tvalid_1's binary_logloss: 0.175434\n",
      "[80]\ttraining's auc: 0.998217\ttraining's binary_logloss: 0.0990572\tvalid_1's auc: 0.983748\tvalid_1's binary_logloss: 0.174119\n",
      "[81]\ttraining's auc: 0.998288\ttraining's binary_logloss: 0.0980227\tvalid_1's auc: 0.983726\tvalid_1's binary_logloss: 0.173961\n",
      "[82]\ttraining's auc: 0.998339\ttraining's binary_logloss: 0.0970751\tvalid_1's auc: 0.983736\tvalid_1's binary_logloss: 0.173634\n",
      "[83]\ttraining's auc: 0.998415\ttraining's binary_logloss: 0.0960137\tvalid_1's auc: 0.983766\tvalid_1's binary_logloss: 0.173305\n",
      "[84]\ttraining's auc: 0.998491\ttraining's binary_logloss: 0.0950158\tvalid_1's auc: 0.983816\tvalid_1's binary_logloss: 0.173055\n",
      "[85]\ttraining's auc: 0.998568\ttraining's binary_logloss: 0.0941\tvalid_1's auc: 0.98386\tvalid_1's binary_logloss: 0.17286\n",
      "[86]\ttraining's auc: 0.998667\ttraining's binary_logloss: 0.0928768\tvalid_1's auc: 0.984006\tvalid_1's binary_logloss: 0.171934\n",
      "[87]\ttraining's auc: 0.998725\ttraining's binary_logloss: 0.0920371\tvalid_1's auc: 0.984025\tvalid_1's binary_logloss: 0.17173\n",
      "[88]\ttraining's auc: 0.998783\ttraining's binary_logloss: 0.0911824\tvalid_1's auc: 0.984162\tvalid_1's binary_logloss: 0.171149\n",
      "[89]\ttraining's auc: 0.998833\ttraining's binary_logloss: 0.0899702\tvalid_1's auc: 0.984262\tvalid_1's binary_logloss: 0.170292\n",
      "[90]\ttraining's auc: 0.99889\ttraining's binary_logloss: 0.0887221\tvalid_1's auc: 0.984385\tvalid_1's binary_logloss: 0.169451\n",
      "[91]\ttraining's auc: 0.998935\ttraining's binary_logloss: 0.0878431\tvalid_1's auc: 0.984312\tvalid_1's binary_logloss: 0.169507\n",
      "[92]\ttraining's auc: 0.999001\ttraining's binary_logloss: 0.086863\tvalid_1's auc: 0.984339\tvalid_1's binary_logloss: 0.169062\n",
      "[93]\ttraining's auc: 0.99905\ttraining's binary_logloss: 0.0854374\tvalid_1's auc: 0.984472\tvalid_1's binary_logloss: 0.16775\n",
      "[94]\ttraining's auc: 0.999115\ttraining's binary_logloss: 0.0846801\tvalid_1's auc: 0.984459\tvalid_1's binary_logloss: 0.167767\n",
      "[95]\ttraining's auc: 0.999148\ttraining's binary_logloss: 0.0838005\tvalid_1's auc: 0.984481\tvalid_1's binary_logloss: 0.167423\n",
      "[96]\ttraining's auc: 0.999216\ttraining's binary_logloss: 0.0829284\tvalid_1's auc: 0.984391\tvalid_1's binary_logloss: 0.167689\n",
      "[97]\ttraining's auc: 0.999261\ttraining's binary_logloss: 0.0821307\tvalid_1's auc: 0.984471\tvalid_1's binary_logloss: 0.16748\n",
      "[98]\ttraining's auc: 0.999308\ttraining's binary_logloss: 0.0813471\tvalid_1's auc: 0.984431\tvalid_1's binary_logloss: 0.167432\n",
      "[99]\ttraining's auc: 0.999338\ttraining's binary_logloss: 0.0805305\tvalid_1's auc: 0.984391\tvalid_1's binary_logloss: 0.167287\n",
      "[100]\ttraining's auc: 0.999378\ttraining's binary_logloss: 0.0798322\tvalid_1's auc: 0.984398\tvalid_1's binary_logloss: 0.167312\n",
      "Execution time: 0.35916948318481445 seconds\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "print(lgb.__version__)\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 1000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(n_estimators = 100)\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "#force larger number of max trees and smaller learning rate\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric='AUC')\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76fd612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93550\n",
      "Precision: 0.92913\n",
      "Sensitivity: 0.94306\n",
      "Specificity: 0.92793\n",
      "F-measure: 0.93604\n",
      "Confusion matrix:\n",
      "[[927  72]\n",
      " [ 57 944]]\n",
      "AUC:  0.9354924354924354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "accuracy = (tn + tp) / (tp + tn +  fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "f_measure = (2*precision*sensitivity) / (precision + sensitivity)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "\n",
    "eval_result = clf.evals_result_\n",
    "\n",
    "with open('lgbm_acc.csv', 'w') as f:\n",
    "    for acc in clf.evals_result_['training']['auc']:\n",
    "        f.write(\"%s,\\n\"%(acc))\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.5f}\")\n",
    "print(f\"Specificity: {specificity:.5f}\")\n",
    "print(f\"F-measure: {f_measure:.5f}\")\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\")\n",
    "print(\"AUC: \", auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7348a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.90570\tvalidation_1-auc:0.89227\n",
      "[1]\tvalidation_0-auc:0.93849\tvalidation_1-auc:0.91693\n",
      "[2]\tvalidation_0-auc:0.94446\tvalidation_1-auc:0.92493\n",
      "[3]\tvalidation_0-auc:0.95073\tvalidation_1-auc:0.93222\n",
      "[4]\tvalidation_0-auc:0.96387\tvalidation_1-auc:0.94302\n",
      "[5]\tvalidation_0-auc:0.96988\tvalidation_1-auc:0.94858\n",
      "[6]\tvalidation_0-auc:0.97269\tvalidation_1-auc:0.94976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tvalidation_0-auc:0.97612\tvalidation_1-auc:0.95376\n",
      "[8]\tvalidation_0-auc:0.97802\tvalidation_1-auc:0.95629\n",
      "[9]\tvalidation_0-auc:0.98295\tvalidation_1-auc:0.96181\n",
      "[10]\tvalidation_0-auc:0.98459\tvalidation_1-auc:0.96356\n",
      "[11]\tvalidation_0-auc:0.98662\tvalidation_1-auc:0.96661\n",
      "[12]\tvalidation_0-auc:0.98957\tvalidation_1-auc:0.96971\n",
      "[13]\tvalidation_0-auc:0.99072\tvalidation_1-auc:0.97073\n",
      "[14]\tvalidation_0-auc:0.99163\tvalidation_1-auc:0.97175\n",
      "[15]\tvalidation_0-auc:0.99188\tvalidation_1-auc:0.97229\n",
      "[16]\tvalidation_0-auc:0.99283\tvalidation_1-auc:0.97390\n",
      "[17]\tvalidation_0-auc:0.99357\tvalidation_1-auc:0.97478\n",
      "[18]\tvalidation_0-auc:0.99388\tvalidation_1-auc:0.97525\n",
      "[19]\tvalidation_0-auc:0.99430\tvalidation_1-auc:0.97565\n",
      "[20]\tvalidation_0-auc:0.99480\tvalidation_1-auc:0.97603\n",
      "[21]\tvalidation_0-auc:0.99496\tvalidation_1-auc:0.97605\n",
      "[22]\tvalidation_0-auc:0.99524\tvalidation_1-auc:0.97598\n",
      "[23]\tvalidation_0-auc:0.99614\tvalidation_1-auc:0.97746\n",
      "[24]\tvalidation_0-auc:0.99651\tvalidation_1-auc:0.97849\n",
      "[25]\tvalidation_0-auc:0.99689\tvalidation_1-auc:0.97851\n",
      "[26]\tvalidation_0-auc:0.99703\tvalidation_1-auc:0.97865\n",
      "[27]\tvalidation_0-auc:0.99723\tvalidation_1-auc:0.97922\n",
      "[28]\tvalidation_0-auc:0.99753\tvalidation_1-auc:0.97907\n",
      "[29]\tvalidation_0-auc:0.99769\tvalidation_1-auc:0.97910\n",
      "[30]\tvalidation_0-auc:0.99789\tvalidation_1-auc:0.97961\n",
      "[31]\tvalidation_0-auc:0.99825\tvalidation_1-auc:0.97971\n",
      "[32]\tvalidation_0-auc:0.99860\tvalidation_1-auc:0.98044\n",
      "[33]\tvalidation_0-auc:0.99871\tvalidation_1-auc:0.98055\n",
      "[34]\tvalidation_0-auc:0.99875\tvalidation_1-auc:0.98052\n",
      "[35]\tvalidation_0-auc:0.99887\tvalidation_1-auc:0.98049\n",
      "[36]\tvalidation_0-auc:0.99891\tvalidation_1-auc:0.98050\n",
      "[37]\tvalidation_0-auc:0.99909\tvalidation_1-auc:0.98025\n",
      "[38]\tvalidation_0-auc:0.99925\tvalidation_1-auc:0.97999\n",
      "[39]\tvalidation_0-auc:0.99928\tvalidation_1-auc:0.97999\n",
      "[40]\tvalidation_0-auc:0.99937\tvalidation_1-auc:0.98005\n",
      "[41]\tvalidation_0-auc:0.99948\tvalidation_1-auc:0.98003\n",
      "[42]\tvalidation_0-auc:0.99954\tvalidation_1-auc:0.98033\n",
      "[43]\tvalidation_0-auc:0.99957\tvalidation_1-auc:0.98072\n",
      "[44]\tvalidation_0-auc:0.99965\tvalidation_1-auc:0.98119\n",
      "[45]\tvalidation_0-auc:0.99968\tvalidation_1-auc:0.98154\n",
      "[46]\tvalidation_0-auc:0.99971\tvalidation_1-auc:0.98168\n",
      "[47]\tvalidation_0-auc:0.99973\tvalidation_1-auc:0.98165\n",
      "[48]\tvalidation_0-auc:0.99977\tvalidation_1-auc:0.98162\n",
      "[49]\tvalidation_0-auc:0.99981\tvalidation_1-auc:0.98176\n",
      "[50]\tvalidation_0-auc:0.99984\tvalidation_1-auc:0.98198\n",
      "[51]\tvalidation_0-auc:0.99989\tvalidation_1-auc:0.98190\n",
      "[52]\tvalidation_0-auc:0.99992\tvalidation_1-auc:0.98211\n",
      "[53]\tvalidation_0-auc:0.99993\tvalidation_1-auc:0.98204\n",
      "[54]\tvalidation_0-auc:0.99995\tvalidation_1-auc:0.98216\n",
      "[55]\tvalidation_0-auc:0.99996\tvalidation_1-auc:0.98218\n",
      "[56]\tvalidation_0-auc:0.99996\tvalidation_1-auc:0.98212\n",
      "[57]\tvalidation_0-auc:0.99998\tvalidation_1-auc:0.98223\n",
      "[58]\tvalidation_0-auc:0.99998\tvalidation_1-auc:0.98244\n",
      "[59]\tvalidation_0-auc:0.99998\tvalidation_1-auc:0.98272\n",
      "[60]\tvalidation_0-auc:0.99998\tvalidation_1-auc:0.98289\n",
      "[61]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.98272\n",
      "[62]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.98287\n",
      "[63]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.98286\n",
      "[64]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.98285\n",
      "[65]\tvalidation_0-auc:0.99999\tvalidation_1-auc:0.98304\n",
      "[66]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98302\n",
      "[67]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98345\n",
      "[68]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98346\n",
      "[69]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98360\n",
      "[70]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98418\n",
      "[71]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98410\n",
      "[72]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98398\n",
      "[73]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98433\n",
      "[74]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98433\n",
      "[75]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98441\n",
      "[76]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98474\n",
      "[77]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98493\n",
      "[78]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98492\n",
      "[79]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98495\n",
      "[80]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98498\n",
      "[81]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98507\n",
      "[82]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98498\n",
      "[83]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98492\n",
      "[84]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98511\n",
      "[85]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98504\n",
      "[86]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98499\n",
      "[87]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98504\n",
      "[88]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98519\n",
      "[89]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98516\n",
      "[90]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98544\n",
      "[91]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98543\n",
      "[92]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98549\n",
      "[93]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98549\n",
      "[94]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98566\n",
      "[95]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98564\n",
      "[96]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98567\n",
      "[97]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98564\n",
      "[98]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98565\n",
      "[99]\tvalidation_0-auc:1.00000\tvalidation_1-auc:0.98564\n",
      "Execution time: 1.1661031246185303 seconds\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(tree_method=\"hist\", enable_categorical=True, n_estimators = 100)\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "xgb.fit(X_train,y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric='auc')\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db596a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94000\n",
      "Precision: 0.93485\n",
      "Sensitivity: 0.94605\n",
      "Specificity: 0.93393\n",
      "F-measure: 0.94042\n",
      "Confusion matrix:\n",
      "[[933  66]\n",
      " [ 54 947]]\n",
      "AUC:  0.9399939399939401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "eval_result = xgb.evals_result()\n",
    "\n",
    "with open('xgboost_acc.csv', 'w') as f:\n",
    "    for acc in xgb.evals_result()['validation_0']['auc']:\n",
    "        f.write(\"%s,\\n\"%(acc))\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "accuracy = (tn + tp) / (tp + tn +  fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "f_measure = (2*precision*sensitivity) / (precision + sensitivity)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.5f}\")\n",
    "print(f\"Specificity: {specificity:.5f}\")\n",
    "print(f\"F-measure: {f_measure:.5f}\")\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\")\n",
    "print(\"AUC: \", auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f6f71785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit(y_true, y_pred):\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_pred)\n",
    "    return auc(fpr, tpr)\n",
    "\n",
    "\n",
    "class ProfitMetric:\n",
    "    def is_max_optimal(self):\n",
    "        return True # greater is better\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        y_pred = np.rint(approx)\n",
    "        y_true = np.array(target).astype(int)\n",
    "\n",
    "        output_weight = 1 # weight is not used\n",
    "\n",
    "        score = get_profit(y_true, y_pred)\n",
    " \n",
    "        return score, output_weight\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2eea842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn': {'Logloss': [0.6153587036132813, 0.5620554809570313, 0.5292899169921875, 0.505640869140625, 0.4770231323242187, 0.4538741149902344, 0.43624899291992186, 0.4165221862792969, 0.3908630676269531, 0.3757257080078125, 0.35838912963867187, 0.3430806884765625, 0.33269476318359376, 0.32421871948242187, 0.3168689880371094, 0.30925750732421875, 0.299280029296875, 0.2897782897949219, 0.28376705932617186, 0.27492361450195313, 0.267062255859375, 0.2612080078125, 0.25712942504882813, 0.2521830291748047, 0.24725019836425782, 0.2400380401611328, 0.23624850463867186, 0.23067706298828125, 0.22777169799804686, 0.22276544189453126, 0.21973048400878906, 0.21667724609375, 0.21276495361328124, 0.209555908203125, 0.20723245239257812, 0.2040858917236328, 0.20167816162109375, 0.19961474609375, 0.19693576049804687, 0.19449258422851562, 0.19206414794921875, 0.1899857177734375, 0.18751113891601562, 0.1855792236328125, 0.182436279296875, 0.18038694763183594, 0.17859414672851562, 0.17701930236816407, 0.17601022338867187, 0.17432489013671876, 0.17286636352539062, 0.17078924560546874, 0.168660888671875, 0.16759182739257814, 0.16494520568847656, 0.16396115112304688, 0.1632679901123047, 0.16092236328125, 0.15931161499023438, 0.1582046356201172, 0.156672119140625, 0.1560194091796875, 0.1545972442626953, 0.15242144775390626, 0.15073419189453124, 0.1501649169921875, 0.14826048278808593, 0.14649066162109375, 0.14513475036621093, 0.14375662231445313, 0.14225479125976562, 0.1418489990234375, 0.1404223327636719, 0.1398652648925781, 0.13896852111816407, 0.13834030151367188, 0.13777691650390625, 0.13648497009277344, 0.13490463256835938, 0.13422320556640624, 0.13218118286132813, 0.13166262817382812, 0.129639892578125, 0.1281644287109375, 0.12771749114990236, 0.12631229400634766, 0.12460928344726563, 0.124205322265625, 0.12270355987548828, 0.1222334976196289, 0.12100947570800781, 0.12051282501220703, 0.12040680694580078, 0.11969633483886719, 0.11876339721679688, 0.11786958312988281, 0.11644779968261719, 0.1150609130859375, 0.1142032241821289, 0.11365301513671874]}, 'validation': {'Logloss': [0.6105448860456768, 0.5569374870247102, 0.5213501460477348, 0.49742942084954767, 0.47233139842361915, 0.44947340359647275, 0.4324219351293308, 0.4131368293761976, 0.38978742571003405, 0.37517541326081766, 0.3585816533205633, 0.34288513000769894, 0.333921128872862, 0.32674305936168985, 0.3190725648255699, 0.3116642049270439, 0.3036610565046224, 0.29606523512950067, 0.29044890074411783, 0.2822858891601603, 0.27412996002835494, 0.26853999188071237, 0.2650945969045851, 0.26005089566604694, 0.25622888361000246, 0.24920406741505013, 0.2461564668083042, 0.24108657238545184, 0.23919904407938725, 0.23407120307698756, 0.23172112444805903, 0.22985507448045242, 0.2256749338416161, 0.2225598091323148, 0.2206492221025787, 0.2175373685106107, 0.21596020502324706, 0.21412468398325948, 0.21216391241021748, 0.21046149549557264, 0.20849669931492315, 0.20682083595865694, 0.2044269000602156, 0.20276630616116575, 0.20060491523324878, 0.19975543710750066, 0.19869526937684104, 0.19708306258225847, 0.19693065102736054, 0.19616804853385983, 0.19473592158516195, 0.19259858563557086, 0.19103737166931456, 0.19031427014509003, 0.18771597435624163, 0.18757561140601553, 0.18762434876848957, 0.1862516818998734, 0.1851208398879313, 0.18428610317859695, 0.18314190964962834, 0.18270053602577863, 0.1816206289304057, 0.18037182830444204, 0.17903276605553353, 0.17893561674644506, 0.1777054789971327, 0.1765470852624931, 0.17515865950291012, 0.17412057306167208, 0.17352438825813152, 0.17351376996686266, 0.17295828880850594, 0.17285052952820482, 0.17192136822765547, 0.17177972329279845, 0.17174560122233956, 0.17132957780306188, 0.1703690415789379, 0.16947852685735543, 0.16829598425461825, 0.1684662162674726, 0.16669250506487548, 0.16549728322822402, 0.1651154745802691, 0.16410626261984984, 0.1626101568981813, 0.16257188499085742, 0.1620509739856104, 0.16184218438631806, 0.1610749180415572, 0.1610706186130429, 0.16110074599098312, 0.16079141664579338, 0.16009855239640072, 0.1598864916776511, 0.1590536703564069, 0.15832217539404966, 0.15818486999800851, 0.1580795585888389], 'AUC': [0.8442283442283443, 0.8855753855753856, 0.9028424028424028, 0.9131559131559132, 0.9301109301109302, 0.935020935020935, 0.939041439041439, 0.9436479436479437, 0.9517449517449518, 0.9568199568199568, 0.9591654591654591, 0.9634949634949634, 0.9653949653949654, 0.9658139658139658, 0.9672469672469672, 0.9690499690499691, 0.9695909695909696, 0.9708849708849708, 0.9717679717679718, 0.9732269732269733, 0.9751089751089751, 0.9754679754679755, 0.9762109762109762, 0.9763039763039763, 0.9768679768679769, 0.9776749776749777, 0.9778889778889779, 0.9787709787709787, 0.9790029790029791, 0.9801269801269801, 0.9803789803789804, 0.9804029804029804, 0.981058981058981, 0.9813779813779814, 0.9813979813979814, 0.9819089819089819, 0.981965981965982, 0.9822939822939823, 0.9823749823749823, 0.9825769825769826, 0.9828849828849829, 0.9830569830569831, 0.9832969832969833, 0.9834469834469834, 0.9836439836439836, 0.9835019835019835, 0.9836809836809837, 0.9838609838609839, 0.9838009838009838, 0.9838169838169838, 0.984034984034984, 0.9842879842879843, 0.9844749844749845, 0.9844709844709845, 0.9847099847099847, 0.9846709846709847, 0.9845679845679846, 0.9846769846769847, 0.9848229848229848, 0.9847279847279847, 0.9849059849059849, 0.9849939849939849, 0.9851089851089851, 0.9851909851909851, 0.9853849853849854, 0.9854029854029854, 0.9855119855119855, 0.9856309856309856, 0.9857969857969858, 0.9859429859429859, 0.9858429858429858, 0.9858029858029858, 0.9858659858659858, 0.9859019859019859, 0.986023986023986, 0.986023986023986, 0.9860169860169861, 0.986038986038986, 0.986077986077986, 0.9862059862059862, 0.9863329863329864, 0.9862649862649863, 0.9863709863709864, 0.9865349865349865, 0.9865799865799866, 0.9866719866719866, 0.9868019868019868, 0.9868179868179868, 0.9868379868379868, 0.9868859868859868, 0.9869459869459869, 0.9869449869449869, 0.986943986943987, 0.986959986959987, 0.987012987012987, 0.987013987013987, 0.987050987050987, 0.987068987068987, 0.987049987049987, 0.9870409870409871]}}\n",
      "Accuracy: 0.94800\n",
      "Precision: 0.94627\n",
      "Sensitivity: 0.95005\n",
      "Specificity: 0.94595\n",
      "F-measure: 0.94816\n",
      "Confusion matrix:\n",
      "[[945  54]\n",
      " [ 50 951]]\n",
      "AUC:  0.947997947997948\n",
      "Execution time: 0.8875970840454102 seconds\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "\n",
    "\n",
    "cols = X.columns\n",
    "num_cols = X._get_numeric_data().columns\n",
    "cat_features = list(set(cols) - set(num_cols))\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "\n",
    "clf = CatBoostClassifier(iterations = 100, verbose = False, eval_metric = 'AUC')\n",
    "\n",
    "clf.fit(X_train, y_train, \n",
    "        cat_features=cat_features, eval_set=(X_test, y_test))\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "\n",
    "# params = {\"iterations\": 100,\n",
    "#           \"depth\": 2,\n",
    "#           \"verbose\": False,\n",
    "#           \"early_stopping_rounds\": 10\n",
    "#         }\n",
    "\n",
    "# scores = cv(cv_dataset,\n",
    "#             params,\n",
    "#             fold_count=2, \n",
    "#             plot=\"True\")\n",
    "\n",
    "print(clf.get_evals_result())\n",
    "\n",
    "with open('catboost_acc.csv', 'w') as f:\n",
    "    for acc in clf.get_evals_result()['validation']['AUC']:\n",
    "        f.write(\"%s,\\n\"%(acc))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "accuracy = (tn + tp) / (tp + tn +  fn + fp)\n",
    "precision = tp / (tp + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "f_measure = (2*precision*sensitivity) / (precision + sensitivity)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.5f}\")\n",
    "print(f\"Precision: {precision:.5f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.5f}\")\n",
    "print(f\"Specificity: {specificity:.5f}\")\n",
    "print(f\"F-measure: {f_measure:.5f}\")\n",
    "print(f\"Confusion matrix:\\n{conf_matrix}\")\n",
    "print(\"AUC: \", auc(fpr, tpr))\n",
    "print('Execution time:', elapsed_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dba0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
